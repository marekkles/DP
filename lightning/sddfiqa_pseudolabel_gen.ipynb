{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from scipy.stats import wasserstein_distance\n",
    "from statistics import mean\n",
    "def chunks(a, b, n):\n",
    "    assert a.shape[0] == b.shape[0], \"Unequal array sizes\"\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(a), n):\n",
    "        yield a[i:i + n], b[i:i + n]\n",
    "def cos_sim(a,b):\n",
    "    return np.dot(a, b.T) / (np.linalg.norm(a, axis=1) * np.linalg.norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=12\n",
    "m=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = IrisVerificationDatasetPseudo('../../Datasets/', [\n",
    "    'train_iris_casia_v4', 'train_iris_nd_0405', \n",
    "    'train_iris_nd_crosssensor_2013', 'train_iris_utris_v1'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids= np.arange(len(ds.annotations), dtype=np.int32)\n",
    "image_classes = np.zeros(len(ds.annotations), dtype=np.int32)\n",
    "image_ids_string = np.array([a['__image_id'] for a in ds.annotations])\n",
    "\n",
    "for image_idx, annotation in enumerate(ds.annotations):\n",
    "    image_classes[image_idx] = annotation['__class_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating random pairs and impostors:: 100%|██████████| 170280/170280 [02:58<00:00, 952.87it/s] \n"
     ]
    }
   ],
   "source": [
    "permute_dict = {} #image id: (pairs: samples of pairs, impostros: samples of impostors)\n",
    "for image_idx in tqdm(image_ids, \"Generating random pairs and impostors:\"):\n",
    "    image_cls = image_classes[image_idx]\n",
    "    image_id_str = image_ids_string[image_idx]\n",
    "\n",
    "    image_ids_pair = image_ids[np.logical_and(image_classes == image_cls, image_ids != image_idx)]\n",
    "    image_ids_impostor = image_ids[image_classes != image_cls]\n",
    "\n",
    "    permute_dict[image_id_str] = (\n",
    "        tuple(image_ids_string[np.random.choice(image_ids_pair, m*K)].tolist()),\n",
    "        tuple(image_ids_string[np.random.choice(image_ids_impostor, m*K)].tolist()),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_vec = {}\n",
    "for image_id in image_ids_string:\n",
    "    rand_vec[image_id] = (np.random.rand(512)*2-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_batch = np.zeros((len(rand_vec), 512))\n",
    "idx_to_id = {}\n",
    "id_to_idx = {}\n",
    "\n",
    "for idx, img in enumerate(rand_vec):\n",
    "    id_to_idx[img] = idx\n",
    "    idx_to_id[idx] = img\n",
    "    vector_batch[idx] = rand_vec[img]\n",
    "\n",
    "vector_len = np.linalg.norm(vector_batch, axis=1)\n",
    "one_over_vector_len = 1/vector_len\n",
    "distances_v = np.zeros((len(permute_dict), K*m*2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Wasserstein distances::  68%|██████▊   | 226/333 [05:27<02:40,  1.50s/it]"
     ]
    }
   ],
   "source": [
    "q = {}\n",
    "batch_size=512\n",
    "for start_id in tqdm(range(0,len(permute_dict),batch_size), \"Calculating cosine distances\"):\n",
    "    root_vectors = vector_batch[start_id:start_id+batch_size, :, np.newaxis]\n",
    "    root_one_over = one_over_vector_len[start_id:start_id+batch_size, np.newaxis, np.newaxis]\n",
    "    batch_vectors = np.zeros((batch_size, K*m*2, 512))\n",
    "    batch_one_over = np.zeros((batch_size, K*m*2, 1))\n",
    "\n",
    "    for i in range(start_id, start_id+batch_size):\n",
    "        pair, impostor = permute_dict[image_id]\n",
    "        idxs = np.array(\n",
    "            [id_to_idx[p] for p in pair ] + [id_to_idx[i] for i in impostor], \n",
    "            dtype=np.int32\n",
    "        )\n",
    "        batch_vectors[i-start_id, :, :] = vector_batch[idxs]\n",
    "        batch_one_over[i-start_id, :, :] = one_over_vector_len[idxs, np.newaxis]\n",
    "        \n",
    "        \n",
    "    distances_v[start_id:start_id+batch_size, :] = ((batch_vectors @ root_vectors) * batch_one_over * root_one_over)\n",
    "    #w_distances = np.zeros(K)\n",
    "    #for i in range(0, K*m, m):\n",
    "    #    w_distances[i//m] = wasserstein_distance(v_dist[i:i+m], v_dist[pair_len+i:pair_len+i+m])\n",
    "    #q[image_id] = np.mean(w_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dv  in enumerate(distances_v):\n",
    "    \n",
    "    w_distances = np.zeros(K)\n",
    "    for j in range(0, K*m, m):\n",
    "        w_distances[i//m] = wasserstein_distance(dv[i:i+m], dv[K*m+i:K*m+i+m])\n",
    "    q[image_id] = np.mean(w_distances)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 512, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 576, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((batch_vectors @ root_vectors) * batch_one_over * root_one_over).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 576, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Datasets/pseudo_permutations.pt' ,'wb') as f:\n",
    "    pickle.dump(permute_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504.6970691680908"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "529213234/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
