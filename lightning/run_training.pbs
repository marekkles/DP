#!/bin/bash
#PBS -N pytorch_training
#PBS -q gpu
#PBS -l select=1:ncpus=4:ngpus=2:mem=16gb:gpu_cap=cuda60:scratch_local=10gb
#PBS -l walltime=3:00:00 
#PBS -m ae

# define a DATADIR variable: directory where the input files are taken from and where output will be copied to
DATADIR=/storage/brno3-cerit/home/marekvasko/ # substitute username and path to to your real username and path
SRCDIR=/storage/brno3-cerit/home/marekvasko/DP # substitute username and path to to your real username and path

# append a line to a file "jobs_info.txt" containing the ID of the job, the hostname of node it is run on and the path to a scratch directory
# this information helps to find a scratch directory in case the job fails and you need to remove the scratch directory manually 
echo "$PBS_JOBID is running on node `hostname -f` in a scratch directory $SCRATCHDIR" >> $DATADIR/jobs_info.txt

# test if scratch directory is set
# if scratch directory is not set, issue error message and exit
test -n "$SCRATCHDIR" || { echo >&2 "Variable SCRATCHDIR is not set!"; exit 1; }

/usr/bin/singularity exec /cvmfs/singularity.metacentrum.cz/NGC/PyTorch\:22.01-py3.SIF bash -c 'source venv/bin/activate \n python DP/lightning/train_recognition.py'

# clean the SCRATCH directory
clean_scratch
