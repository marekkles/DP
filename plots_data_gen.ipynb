{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.evaluation import *\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_root = 'runs_mnt'\n",
    "scores = {}\n",
    "qualities = {}\n",
    "\n",
    "datasets_names = {\n",
    "    'iris_verification_NDCSI2013_01_05': 'Notre Damme 2013',\n",
    "    'iris_verification_nd_0405_01_01': 'Notre Damme 0405',\n",
    "    'iris_verification_inno_keymaker_01_01': 'Innovatrics',\n",
    "    'iris_verification_iitd_01_01': 'IITD',\n",
    "}\n",
    "with open('datasets.pickle', 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "comments = {\n",
    "'imOXXb' : ('CrFiqaNet-iresnet18-CrFiqaLoss-imOXXb'              , 'Trained well, gives results, certainty ratio'),\n",
    "'GzGNXb' : ('CrFiqaNet-iresnet50-CrFiqaLoss-GzGNXb'              , 'Trained well, gives results, certainty ratio'),\n",
    "'H1SWXb' : ('CrFiqaNet-magiresnet18-CrFiqaLoss-H1SWXb'           , 'Did not train, loss to high number'),\n",
    "'0IRWXb' : ('CrFiqaNet-mobilenetv3_large-CrFiqaLoss-0IRWXb'      , 'Trained well, certainty ratio'),\n",
    "'0G8VXb' : ('DfsNet-0G8VXb'                                      , 'Refernce with 640x480 input'),\n",
    "'hdpNXb' : ('DfsNet-hdpNXb'                                      , 'Reference with 224x244 input'),\n",
    "'3wDNXb' : ('PfeNet-iresnet50-3wDNXb'                            , 'PFE with ArcFace'),\n",
    "'RyENXb' : ('PfeNet-iresnet50-RyENXb'                            , 'PFE with MagFace'),\n",
    "'YuBXXb' : ('RecognitionNet-iresnet18-MagFaceLoss-YuBXXb'        , 'iResNet18, crop, without fully connected layer'),\n",
    "'0g9LXb' : ('RecognitionNet-iresnet50-ArcFaceLoss-0g9LXb'        , 'Unwrap baseline with ArcFace, without fully connected layer'),\n",
    "'UVyKXb' : ('RecognitionNet-iresnet50-ArcFaceLoss-UVyKXb'        , 'Crop baseline with ArcFace, without fully connected layer'),\n",
    "'DaqKXb' : ('RecognitionNet-iresnet50-MagFaceLoss-DaqKXb'        , 'Crop baseline with MagFace, without fully connected layer'),\n",
    "'ciWLXb' : ('RecognitionNet-iresnet50-MagFaceLoss-ciWLXb'        , 'Unwrap baseline with MagFace, without fully connected layer'),\n",
    "'7B0TXb' : ('RecognitionNet-magiresnet18-MagFaceLoss-7B0TXb'     , 'Showcase of wrong schedule settings'),\n",
    "'xjxTXb' : ('RecognitionNet-magiresnet18-MagFaceLoss-xjxTXb'     , 'Showcase of good schedule setting'),\n",
    "'RMdMXb' : ('RecognitionNet-magiresnet50-ArcFaceLoss-RMdMXb'     , 'Unwraped ArcFace'),\n",
    "'arzKXb' : ('RecognitionNet-magiresnet50-ArcFaceLoss-arzKXb'     , 'Croped ArcFace'),\n",
    "'931RXb' : ('RecognitionNet-magiresnet50-MagFaceLoss-931RXb'     , 'No augment'),\n",
    "'JnGKXb' : ('RecognitionNet-magiresnet50-MagFaceLoss-JnGKXb'     , 'Crop baseline'),\n",
    "'ihfMXb' : ('RecognitionNet-magiresnet50-MagFaceLoss-ihfMXb'     , 'Unwrap baseline'),\n",
    "'vfFRXb' : ('RecognitionNet-magiresnet50-MagFaceLoss-vfFRXb'     , 'Shear + translate'),\n",
    "'PUXTXb' : ('RecognitionNet-mobilenetv3_large-MagFaceLoss-PUXTXb', 'Small MobileNetV3, baseline crop, without fully connected layer'),\n",
    "'BnkOXb' : ('SddFiqaNet-iresnet50-BnkOXb'                        , 'SDDFIQA with labels from DaqKXb, with labels from iResNet50 crop without fc'),\n",
    "'UeIWXb' : ('SddFiqaNet-iresnet50-UeIWXb'                        , 'SDDFIQA with labels from PUXTXb, with labels fomr MobileNetV3'),\n",
    "'UnMWXb' : ('SddFiqaNet-iresnet50-UnMWXb'                        , 'SDDFIQA with labels from 7B0TXb, wrong magiresenet18'),\n",
    "'e9KWXb' : ('SddFiqaNet-iresnet50-e9KWXb'                        , 'SDDFIQA with labels from xjxTXb, small magiresnet18'),\n",
    "'wJJWXb' : ('SddFiqaNet-iresnet50-wJJWXb'                        , 'SDDFIQA with labels from GOTTXb, untrained mobilenetv3'),\n",
    "}\n",
    "def get_data(type, run, runs_root, dataset):\n",
    "    global comments\n",
    "    path = os.path.join(runs_root, comments[run][0], f'{type}-{comments[run][0]}-{dataset}.pickle')\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "def get_det_for_run(run, runs_root, dataset):\n",
    "    global datasets\n",
    "    global scores\n",
    "    if not (dataset+'+'+run) in scores:\n",
    "        embeddings = get_data('embedding', run, runs_root, dataset)\n",
    "        sc = pairs_impostor_scores(datasets[dataset]['pairs'], datasets[dataset]['impostors'], embeddings, 'cosine')\n",
    "        labels, sc, pairs = generate_labels_scores(sc['pairs'], sc['impostors'])\n",
    "        sc = -sc\n",
    "        scores[dataset+'+'+run] = {'labels': labels,'sc': sc, 'pairs': pairs}\n",
    "    else:\n",
    "        sc = scores[dataset+'+'+run]['sc']\n",
    "        labels = scores[dataset+'+'+run]['labels']\n",
    "    return det_curve(labels, sc)\n",
    "def get_magnitude(run, runs_root, dataset):\n",
    "    global datasets\n",
    "    embeddings = get_data('embedding', run, runs_root, dataset)\n",
    "    magnitudes = {}\n",
    "    for id in embeddings:\n",
    "        magnitudes[id] = np.linalg.norm(embeddings[id])\n",
    "    return magnitudes\n",
    "def pfe_quality(log_sigma):\n",
    "    return stats.hmean(log_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = [\n",
    "    'YuBXXb',\n",
    "    '0g9LXb',\n",
    "    'UVyKXb',\n",
    "    'DaqKXb',\n",
    "    'ciWLXb',\n",
    "    '7B0TXb',\n",
    "    'xjxTXb',\n",
    "    'RMdMXb',\n",
    "    'arzKXb',\n",
    "    '931RXb',\n",
    "    'JnGKXb',\n",
    "    'ihfMXb',\n",
    "    'vfFRXb',\n",
    "    'PUXTXb',\n",
    "    'imOXXb',\n",
    "    'GzGNXb',\n",
    "    '0IRWXb',\n",
    "]\n",
    "\n",
    "dets = {}\n",
    "magface_dets = {}\n",
    "\n",
    "for d in datasets:\n",
    "    for run in baselines:\n",
    "        print(f'Loading: {d} {run}')\n",
    "        dets[d+'+'+run] = get_det_for_run(run, runs_root, d)\n",
    "with open('scores.pickle', 'wb') as f:\n",
    "    pickle.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = [\n",
    "'imOXXb',\n",
    "'GzGNXb',\n",
    "'H1SWXb',\n",
    "'0IRWXb',\n",
    "'0G8VXb',\n",
    "'hdpNXb',\n",
    "'3wDNXb',\n",
    "'RyENXb',\n",
    "'YuBXXb',\n",
    "'0g9LXb',\n",
    "'UVyKXb',\n",
    "'DaqKXb',\n",
    "'ciWLXb',\n",
    "'7B0TXb',\n",
    "'xjxTXb',\n",
    "'RMdMXb',\n",
    "'arzKXb',\n",
    "'931RXb',\n",
    "'JnGKXb',\n",
    "'ihfMXb',\n",
    "'vfFRXb',\n",
    "'PUXTXb',\n",
    "'BnkOXb',\n",
    "'UeIWXb',\n",
    "'UnMWXb',\n",
    "'e9KWXb',\n",
    "'wJJWXb',\n",
    "]\n",
    "for d in datasets:\n",
    "    for run in baselines:\n",
    "        print(f'Loading: {d} {run}', end=': ')\n",
    "        runname = comments[run][0]\n",
    "        runroot = os.path.join(runs_root, runname)\n",
    "        net = runname.split('-')[0]\n",
    "        if net == 'RecognitionNet':\n",
    "            print('RecognitionNet')\n",
    "            serfiq_path = os.path.join(runroot, f'quality-serfiq-{runname}-{d}.pickle')\n",
    "            if os.path.isfile(serfiq_path):\n",
    "                print('Found serfiq')\n",
    "                with open(serfiq_path, 'rb') as f:\n",
    "                    qualities[d+'+'+run+'+'+'serfiq'] = pickle.load(f)\n",
    "            qualities[d+'+'+run+'+'+'magnitude'] = get_magnitude(run, runs_root, d)\n",
    "        elif net == 'SddFiqaNet' or net == 'CrFiqaNet' or net == 'DfsNet':\n",
    "            print('QualityNet')\n",
    "            quality_path = os.path.join(runroot, f'quality-{runname}-{d}.pickle')\n",
    "            if os.path.isfile(quality_path):\n",
    "                print('Found quality')\n",
    "                with open(quality_path, 'rb') as f:\n",
    "                    qualities[d+'+'+run] = pickle.load(f)\n",
    "        elif net == 'PfeNet':\n",
    "            print('PfeNet')\n",
    "            pfe_path = os.path.join(runroot, f'deviation-{runname}-{d}.pickle')\n",
    "            if os.path.isfile(pfe_path):\n",
    "                print('Found pfe')\n",
    "                with open(pfe_path, 'rb') as f:\n",
    "                    deviation = pickle.load(f)\n",
    "                qualities[d+'+'+run] = {}\n",
    "                for id in deviation:\n",
    "                    qualities[d+'+'+run][id] = pfe_quality(np.exp(deviation[id]))\n",
    "\n",
    "with open('qualities.pickle', 'wb') as f:\n",
    "    pickle.dump(qualities, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
